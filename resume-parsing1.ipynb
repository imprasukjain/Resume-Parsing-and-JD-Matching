{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import spacy\nimport pickle\nimport random","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-08-04T19:57:58.849900Z","iopub.execute_input":"2023-08-04T19:57:58.850626Z","iopub.status.idle":"2023-08-04T19:57:59.613443Z","shell.execute_reply.started":"2023-08-04T19:57:58.850575Z","shell.execute_reply":"2023-08-04T19:57:59.612274Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"First, we will execute spacy model on a simple sentence just to get familiar with it.","metadata":{}},{"cell_type":"code","source":"test = spacy.load('en')\nsent = '''My name is P Kumar Deb, i stay in Jaipur.\nThe 2023 ICC Cricket World Cup is scheduled for October.'''\n\nts = test(sent)\nfor ent in ts.ents:\n  print(f'{ent.label_.upper():{10}} - {ent.text}')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-04T19:59:04.639190Z","iopub.execute_input":"2023-08-04T19:59:04.639770Z","iopub.status.idle":"2023-08-04T19:59:05.409842Z","shell.execute_reply.started":"2023-08-04T19:59:04.639736Z","shell.execute_reply":"2023-08-04T19:59:05.408889Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"ORG        - P Kumar Deb\nGPE        - Jaipur\nDATE       - 2023\nEVENT      - World Cup\nDATE       - October\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-04T19:59:51.804859Z","iopub.execute_input":"2023-08-04T19:59:51.805234Z","iopub.status.idle":"2023-08-04T19:59:51.816219Z","shell.execute_reply.started":"2023-08-04T19:59:51.805202Z","shell.execute_reply":"2023-08-04T19:59:51.815171Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input/dataset-for-resume-information-retrieval/Alice Clark CV.pdf\n/kaggle/input/dataset-for-resume-information-retrieval/train_data.pkl\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install PyMuPDF ","metadata":{"execution":{"iopub.status.busy":"2023-08-04T19:59:59.602058Z","iopub.execute_input":"2023-08-04T19:59:59.602474Z","iopub.status.idle":"2023-08-04T20:00:09.702973Z","shell.execute_reply.started":"2023-08-04T19:59:59.602439Z","shell.execute_reply":"2023-08-04T20:00:09.701942Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting PyMuPDF\n  Downloading PyMuPDF-1.22.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.1 MB)\n\u001b[K     |████████████████████████████████| 14.1 MB 4.3 MB/s eta 0:00:01    |███▊                            | 1.7 MB 4.3 MB/s eta 0:00:03\n\u001b[?25hInstalling collected packages: PyMuPDF\nSuccessfully installed PyMuPDF-1.22.5\n\u001b[33mWARNING: You are using pip version 20.2.1; however, version 23.2.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nimport fitz\n\nfname = '/kaggle/input/dataset-for-resume-information-retrieval/Alice Clark CV.pdf'\ndoc = fitz.open(fname)\nalice_cv = \"\"\n\nfor page in doc:\n    alice_cv += page.get_text()\n\nprint(alice_cv)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-04T20:01:47.271574Z","iopub.execute_input":"2023-08-04T20:01:47.272193Z","iopub.status.idle":"2023-08-04T20:01:47.299800Z","shell.execute_reply.started":"2023-08-04T20:01:47.272130Z","shell.execute_reply":"2023-08-04T20:01:47.298546Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Alice Clark \nAI / Machine Learning \n \nDelhi, India Email me on Indeed \n• \n20+ years of experience in data handling, design, and development \n• \nData Warehouse: Data analysis, star/snow flake scema data modelling and design specific to \ndata warehousing and business intelligence \n• \nDatabase: Experience in database designing, scalability, back-up and recovery, writing and \noptimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes. \nCloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL Azure, \nStream Analytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure data lake \nanalytics(U-SQL) \nWilling to relocate anywhere \n \nWORK EXPERIENCE \nSoftware Engineer \nMicrosoft – Bangalore, Karnataka \nJanuary 2000 to Present \n1. Microsoft Rewards Live dashboards: \nDescription: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping \nonline. Microsoft Rewards members can earn points when searching with Bing, browsing with \nMicrosoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft \nStore. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft \nrewards website. Rewards live dashboards gives a live picture of usage world-wide and by \nmarkets like US, Canada, Australia, new user registration count, top/bottom performing rewards \noffers, orders stats and weekly trends of user activities, orders and new user registrations. the \nPBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes. \nTechnology/Tools used \n \nEDUCATION \nIndian Institute of Technology – Mumbai \n2001 \n \nSKILLS \nMachine Learning, Natural Language Processing, and Big Data Handling \n \nADDITIONAL INFORMATION \nProfessional Skills \n• Excellent analytical, problem solving, communication, knowledge transfer and interpersonal \nskills with ability to interact with individuals at all the levels \n• Quick learner and maintains cordial relationship with project manager and team members and \ngood performer both in team and independent job environments \n• Positive attitude towards superiors &amp; peers \n• Supervised junior developers throughout project lifecycle and provided technical assistance \n\n","output_type":"stream"}]},{"cell_type":"code","source":"fname = '/kaggle/input/resume/resume3.pdf'\ndoc = fitz.open(fname)\nresume_3 = \"\"\n\nfor page in doc:\n    resume_3 += page.get_text()\n\nprint(resume_3)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-04T20:36:57.496824Z","iopub.execute_input":"2023-08-04T20:36:57.497260Z","iopub.status.idle":"2023-08-04T20:36:57.544494Z","shell.execute_reply.started":"2023-08-04T20:36:57.497222Z","shell.execute_reply":"2023-08-04T20:36:57.543176Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Nivetha B \nLooking for an exciting role as a student intern to utilize my development skills for the growth of the organization\nas well as to enhance my knowledge. \nnivethabalaji1312@gmail.com \n8925706279 \nChennai, Tamilnadu. \nlinkedin.com/in/nivetha-balaji \ngithub.com/Nivetha1312 \nEDUCATION \nMSc Data Science \nPSG College of Technology \n2019 - 2024,  \n8.07 CGPA \nXII(Higher Secondary, State Board) \nBharathidhasanar Matriculation Higher Secondary\nSchool, Arakkonam. \n2018 - 2019,  \n91.8% \nX(SSLC, State Board) \nBharathidhasanar Matriculation Higher Secondary\nSchool, Arakkonam. \n2016 - 2017,  \n96.6% \nPROJECTS \nImagado \nAn application developed using Python, trained using the dataset\ncomprising 30 pictures each of six famous personalities. The purpose of\nthis project is to achieve student attendance marking, which is capable\nof identifying a person from their digital image. This task is\naccomplished using Logistic Regression due to greater accuracy. \nTime for the Trend \nA project developed in Tableau, is used to analyze live YouTube data.\nTableau helps in building charts, which are then published in Tableau\npublic. The embed code is later extracted and projected on the web\npage. This idea is to display the work in the web page. \nFake Hack \nA machine learning project that classiﬁes the text in the dataset as fake\nor true which is done using algorithms such as Logistic Regression,\nDecision Trees and Random Forest classiﬁers with Decision Trees proved\nto be the best model providing the highest accuracy. \nData Storey \nAn application developed in C++ using AVL and Splay Trees. The project\naims to manage the cache memory eﬀectively. The recent access\nproperty of splay tree assists in cache memory management. \nLearnpal \nA web-based student-staﬀ portal was developed using HTML, CSS. This\nhelps keep the students aware of their attendance and grades, and the\nstaﬀ members of their attendance and feedback. \nSKILLS \nPython \nC++ \nC \nHTML \nCSS \nSQL \nTableau \nVSCode \nSpyder \nWireshark \nEXTRA CURRICULAR\nACTIVITIES \nRunner-up in the Code Hunt event\nheld at PSG College of Technology,\nCoimbatore. \nRunner-up in Zone Level Volleyball\nheld at Selvam Matric. Higher\nSecondary School, Arakkonam. \nRunner-up in Zone Level Volleyball\nheld at Government Girls Higher\nSecondary School, Arakkonam. \nLANGUAGES \nEnglish \nFull Professional Proﬁciency \nTamil \nFull Professional Proﬁciency \nTelugu \nNative or Bilingual Proﬁciency \nINTERESTS \nDatabase Management system \nOperating system \nSupervised and Unsupervised\nLearning \n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we can pass our test data on our pre trained spacy model and evaluate how good it has performed.","metadata":{}},{"cell_type":"code","source":"test = spacy.load('en')\nts = test(\" \".join(alice_cv.split('\\n'))) # we have splitted our data with '\\n' and rejoined with space. ","metadata":{"execution":{"iopub.status.busy":"2023-08-04T20:01:54.573550Z","iopub.execute_input":"2023-08-04T20:01:54.574172Z","iopub.status.idle":"2023-08-04T20:01:55.381999Z","shell.execute_reply.started":"2023-08-04T20:01:54.574112Z","shell.execute_reply":"2023-08-04T20:01:55.380868Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**ts** variable contains all POS tags,NER etc in it. We will extract only NER and manually verify output.","metadata":{}},{"cell_type":"code","source":"for ent in ts.ents:\n  if ent.label_.upper() == 'PERSON':\n    print(f'{ent.label_.upper():{10}} - {ent.text}')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T20:01:59.349042Z","iopub.execute_input":"2023-08-04T20:01:59.349465Z","iopub.status.idle":"2023-08-04T20:01:59.372746Z","shell.execute_reply.started":"2023-08-04T20:01:59.349432Z","shell.execute_reply":"2023-08-04T20:01:59.371077Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"PERSON     - Alice Clark\nPERSON     - Stored Procedures\nPERSON     - Cloud\nPERSON     - Document DB\nPERSON     - Web Job\nPERSON     - Web App\nPERSON     - Bing\n","output_type":"stream"}]},{"cell_type":"code","source":"for ent in ts.ents:\n  if ent.label_.upper() == 'ORG':\n    print(f'{ent.label_.upper():{10}} - {ent.text}')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T20:02:05.428178Z","iopub.execute_input":"2023-08-04T20:02:05.428771Z","iopub.status.idle":"2023-08-04T20:02:05.437055Z","shell.execute_reply.started":"2023-08-04T20:02:05.428720Z","shell.execute_reply":"2023-08-04T20:02:05.436003Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"ORG        - AI / Machine Learning\nORG        - star/snow flake scema\nORG        - SQL\nORG        - Microsoft Azure\nORG        - SQL Azure\nORG        - Stream Analytics\nORG        - Power BI\nORG        - Power BI\nORG        - SQL\nORG        - Microsoft\nORG        - Microsoft\nORG        - Microsoft\nORG        - Microsoft\nORG        - Microsoft Edge\nORG        - Microsoft\nORG        - Microsoft\nORG        - PBI\nORG        - Technology/Tools\nORG        - Indian Institute of Technology\nORG        - Big Data\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = pickle.load(open('/kaggle/input/dataset-for-resume-information-retrieval/train_data.pkl','rb'))\nprint(f\"Training data consist of {len(train_data)} manually labelled resume's.\")","metadata":{"execution":{"iopub.status.busy":"2023-08-04T20:02:12.742567Z","iopub.execute_input":"2023-08-04T20:02:12.742972Z","iopub.status.idle":"2023-08-04T20:02:12.775957Z","shell.execute_reply.started":"2023-08-04T20:02:12.742938Z","shell.execute_reply":"2023-08-04T20:02:12.775051Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Training data consist of 200 manually labelled resume's.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data[97]","metadata":{"execution":{"iopub.status.busy":"2023-08-04T20:02:19.919487Z","iopub.execute_input":"2023-08-04T20:02:19.920228Z","iopub.status.idle":"2023-08-04T20:02:19.928541Z","shell.execute_reply.started":"2023-08-04T20:02:19.920184Z","shell.execute_reply":"2023-08-04T20:02:19.927422Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"('Ramesh chokkala Telangana - Email me on Indeed: indeed.com/r/Ramesh-chokkala/16d5fa56f8c19eb6  WORK EXPERIENCE  software  Microsoft,Infosis, Google -  May 2018 to Present  software  Microsoft,Infosis, Google -  May 2018 to Present  EDUCATION  btech  Trinity engineering college  https://www.indeed.com/r/Ramesh-chokkala/16d5fa56f8c19eb6?isid=rex-download&ikw=download-top&co=IN',\n {'entities': [(250, 278, 'College Name'),\n   (243, 248, 'Degree'),\n   (182, 207, 'Companies worked at'),\n   (172, 180, 'Designation'),\n   (122, 147, 'Companies worked at'),\n   (112, 120, 'Designation'),\n   (48, 94, 'Email Address'),\n   (16, 25, 'Location'),\n   (0, 15, 'Name')]})"},"metadata":{}}]},{"cell_type":"code","source":"# loading blank spacy model as we want to customize our model.\n# spacy.blank('en') will create a blank model of a given language class i.e., for here English.\n\nnlp = spacy.blank('en') ","metadata":{"execution":{"iopub.status.busy":"2023-08-04T20:02:25.329910Z","iopub.execute_input":"2023-08-04T20:02:25.330325Z","iopub.status.idle":"2023-08-04T20:02:25.618748Z","shell.execute_reply.started":"2023-08-04T20:02:25.330279Z","shell.execute_reply":"2023-08-04T20:02:25.617675Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Creating a function to train our model\n\ndef train_model(train_data):\n    \n  if 'ner' not in nlp.pipe_names:# Checking if NER is present in pipeline\n    ner = nlp.create_pipe('ner') # creating NER pipe if not present\n    nlp.add_pipe(ner, last=True) # adding NER pipe in the end\n\n  for _, annotation in train_data: # Getting 1 resume at a time from our training data of 200 resumes\n    for ent in annotation['entities']: # Getting each tuple at a time from 'entities' key in dictionary at index[1] i.e.,(0, 15, 'Name') and so on\n      ner.add_label(ent[2])  # here we are adding only labels of each tuple from entities key dict, eg:- 'Name' label of (0, 15, 'Name')\n    \n  # In above for loop we finally added all custom NER from training data.\n    \n\n  other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner'] # getting all other pipes except NER.\n  with nlp.disable_pipes(*other_pipes): # Disabling other pipe's as we want to train only NER.\n        optimizer = nlp.begin_training()\n        \n        for itn in range(10):         # trainig model for 10 iteraion\n            print('Starting iteration ' + str(itn))\n            random.shuffle(train_data) # shuffling data in every iteration \n            losses = {}\n            for text, annotations in train_data:\n              try:\n                nlp.update(\n                    [text],        #batch of texts\n                    [annotations], #batch of annotations\n                    drop=0.2,      #dropout rate -makes it harder to memorise\n                    sgd=optimizer, #callable to update weights\n                    losses=losses) #Dictionary to update with the loss, keyed by pipeline component.\n              except Exception as e:\n                pass","metadata":{"execution":{"iopub.status.busy":"2023-08-04T20:02:30.946199Z","iopub.execute_input":"2023-08-04T20:02:30.946568Z","iopub.status.idle":"2023-08-04T20:02:30.957311Z","shell.execute_reply.started":"2023-08-04T20:02:30.946539Z","shell.execute_reply":"2023-08-04T20:02:30.955844Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_model(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T20:02:36.960716Z","iopub.execute_input":"2023-08-04T20:02:36.961107Z","iopub.status.idle":"2023-08-04T20:05:21.238359Z","shell.execute_reply.started":"2023-08-04T20:02:36.961070Z","shell.execute_reply":"2023-08-04T20:05:21.237257Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Starting iteration 0\nStarting iteration 1\nStarting iteration 2\nStarting iteration 3\nStarting iteration 4\nStarting iteration 5\nStarting iteration 6\nStarting iteration 7\nStarting iteration 8\nStarting iteration 9\n","output_type":"stream"}]},{"cell_type":"code","source":"nlp.to_disk('nlp_model')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T20:28:44.203929Z","iopub.execute_input":"2023-08-04T20:28:44.204384Z","iopub.status.idle":"2023-08-04T20:28:44.253550Z","shell.execute_reply.started":"2023-08-04T20:28:44.204346Z","shell.execute_reply":"2023-08-04T20:28:44.252509Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"nlp_model = spacy.load('nlp_model')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T20:28:50.550728Z","iopub.execute_input":"2023-08-04T20:28:50.551098Z","iopub.status.idle":"2023-08-04T20:28:51.094525Z","shell.execute_reply.started":"2023-08-04T20:28:50.551066Z","shell.execute_reply":"2023-08-04T20:28:51.093286Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"nlp_model.entity.labels","metadata":{"execution":{"iopub.status.busy":"2023-08-04T20:28:54.539802Z","iopub.execute_input":"2023-08-04T20:28:54.540448Z","iopub.status.idle":"2023-08-04T20:28:54.548843Z","shell.execute_reply.started":"2023-08-04T20:28:54.540391Z","shell.execute_reply":"2023-08-04T20:28:54.547709Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"('College Name',\n 'Companies worked at',\n 'Degree',\n 'Designation',\n 'Email Address',\n 'Graduation Year',\n 'Location',\n 'Name',\n 'Skills',\n 'UNKNOWN',\n 'Years of Experience')"},"metadata":{}}]},{"cell_type":"code","source":"doc = nlp_model(\" \".join(alice_cv.split('\\n')))\nfor ent in doc.ents:\n  print(f'{ent.label_.upper():{20}} - {ent.text}')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T20:34:45.351126Z","iopub.execute_input":"2023-08-04T20:34:45.351558Z","iopub.status.idle":"2023-08-04T20:34:45.379304Z","shell.execute_reply.started":"2023-08-04T20:34:45.351526Z","shell.execute_reply":"2023-08-04T20:34:45.378305Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"NAME                 - Alice Clark\nLOCATION             - Delhi\nCOMPANIES WORKED AT  - Microsoft Azure\nDESIGNATION          - Software Engineer\nCOMPANIES WORKED AT  - Microsoft\nCOMPANIES WORKED AT  - Microsoft\nCOMPANIES WORKED AT  - Microsoft\nCOMPANIES WORKED AT  - Microsoft\nCOMPANIES WORKED AT  - Microsoft\nCOMPANIES WORKED AT  - Microsoft\nCOMPANIES WORKED AT  - Microsoft\nCOLLEGE NAME         - Indian Institute of Technology – Mumbai\nSKILLS               - Machine Learning, Natural Language Processing, and Big Data Handling    ADDITIONAL INFORMATION  Professional Skills  • Excellent analytical, problem solving, communication, knowledge transfer and interpersonal\n","output_type":"stream"}]},{"cell_type":"markdown","source":"From above output we can clearly see that our custom trained spacy model has worked very well and labelled our testing data correctly but not 100% as the skills are not mentioned in output. This could be due to less training data. To increase accuracy we should train our model on different formats of data.","metadata":{}},{"cell_type":"code","source":"doc = nlp_model(\" \".join(resume_3.split('\\n')))\nfor ent in doc.ents:\n  print(f'{ent.label_.upper():{20}} - {ent.text}')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T20:37:34.470688Z","iopub.execute_input":"2023-08-04T20:37:34.471526Z","iopub.status.idle":"2023-08-04T20:37:34.513575Z","shell.execute_reply.started":"2023-08-04T20:37:34.471472Z","shell.execute_reply":"2023-08-04T20:37:34.512513Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"NAME                 - Nivetha B\nDEGREE               - MSc Data Science\nCOMPANIES WORKED AT  - PSG College\nDEGREE               - Python\nCOMPANIES WORKED AT  - PSG College\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}